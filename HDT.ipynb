{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hoja de trabajo 2\n",
    "- Paola de León 20361\n",
    "- Paola Contreras 20213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TASK 1  - Preparación del conjunto de datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([120, 4])\n",
      "y_train: torch.Size([120])\n",
      "X_val: torch.Size([30, 4])\n",
      "y_val: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data  \n",
    "y = iris.target  \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir los datos en tensores de PyTorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2 - Arquitectura modelo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Basado en  https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, entrada, salida, ocultas):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(entrada,ocultas[0])  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(ocultas[0], ocultas[1])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(ocultas[1], salida)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "entrada = X_train.shape[1]\n",
    "salida = 4\n",
    "ocultas = [64,32]\n",
    "\n",
    "model = Net(entrada, salida, ocultas)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 3 - Funciones de Pérdida*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear conjuntos de datos y DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [10/100], Train Loss: 0.3580, Val Loss: 0.3220\n",
      "Época [20/100], Train Loss: 0.1759, Val Loss: 0.1763\n",
      "Época [30/100], Train Loss: 0.1235, Val Loss: 0.1471\n",
      "Época [40/100], Train Loss: 0.1386, Val Loss: 0.1023\n",
      "Época [50/100], Train Loss: 0.1241, Val Loss: 0.0907\n",
      "Época [60/100], Train Loss: 0.1162, Val Loss: 0.3257\n",
      "Época [70/100], Train Loss: 0.1073, Val Loss: 0.1960\n",
      "Época [80/100], Train Loss: 0.0829, Val Loss: 0.0893\n",
      "Época [90/100], Train Loss: 0.1036, Val Loss: 0.1378\n",
      "Época [100/100], Train Loss: 0.1268, Val Loss: 0.0997\n"
     ]
    }
   ],
   "source": [
    "# Cross Entropy Loss\n",
    "lr = 0.01\n",
    "num_epochs = 100\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Modo de evaluación en datos de prueba\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Imprimir información de entrenamiento y validación\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Época [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Contreras GP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\Contreras GP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.0482, Test Loss: 0.0518\n",
      "Epoch [20/100], Train Loss: 0.0445, Test Loss: 0.0482\n",
      "Epoch [30/100], Train Loss: 0.0436, Test Loss: 0.0468\n",
      "Epoch [40/100], Train Loss: 0.0400, Test Loss: 0.0566\n",
      "Epoch [50/100], Train Loss: 0.0412, Test Loss: 0.0439\n",
      "Epoch [60/100], Train Loss: 0.0401, Test Loss: 0.0628\n",
      "Epoch [70/100], Train Loss: 0.0425, Test Loss: 0.0449\n",
      "Epoch [80/100], Train Loss: 0.0388, Test Loss: 0.0437\n",
      "Epoch [90/100], Train Loss: 0.0411, Test Loss: 0.0435\n",
      "Epoch [100/100], Train Loss: 0.0396, Test Loss: 0.0434\n"
     ]
    }
   ],
   "source": [
    "#  Mean Squared Error\n",
    "lr = 0.01\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets.view(-1, 1).float()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Evaluation mode on test data\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets.view(-1, 1))  \n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Print training and validation information\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Contreras GP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "c:\\Users\\Contreras GP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.0193, Test Loss: 0.0240\n",
      "Epoch [20/100], Train Loss: 0.0193, Test Loss: 0.0220\n",
      "Epoch [30/100], Train Loss: 0.0190, Test Loss: 0.0227\n",
      "Epoch [40/100], Train Loss: 0.0190, Test Loss: 0.0243\n",
      "Epoch [50/100], Train Loss: 0.0189, Test Loss: 0.0235\n",
      "Epoch [60/100], Train Loss: 0.0184, Test Loss: 0.0218\n",
      "Epoch [70/100], Train Loss: 0.0189, Test Loss: 0.0229\n",
      "Epoch [80/100], Train Loss: 0.0186, Test Loss: 0.0227\n",
      "Epoch [90/100], Train Loss: 0.0192, Test Loss: 0.0224\n",
      "Epoch [100/100], Train Loss: 0.0186, Test Loss: 0.0244\n"
     ]
    }
   ],
   "source": [
    "#  Huber Loss\n",
    "lr = 0.01\n",
    "loss_function = nn.SmoothL1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets.view(-1, 1).float()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Evaluation mode on test data\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets.view(-1, 1))  # Ensure targets match output shape\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Print training and validation information\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
