{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hoja de trabajo 2\n",
    "- Paola de León 20361\n",
    "- Paola Contreras 20213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TASK 1  - Preparación del conjunto de datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([120, 4])\n",
      "y_train: torch.Size([120])\n",
      "X_val: torch.Size([30, 4])\n",
      "y_val: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data  \n",
    "y = iris.target  \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir los datos en tensores de PyTorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2 - Arquitectura modelo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Basado en  https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, entrada, salida, ocultas):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(entrada,ocultas[0])  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(ocultas[0], ocultas[1])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(ocultas[1], salida)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "entrada = X_train.shape[1]\n",
    "salida = 4\n",
    "ocultas = [64,32]\n",
    "\n",
    "model = Net(entrada, salida, ocultas)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 3 - Funciones de Pérdida*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear conjuntos de datos y DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [10/100], Train Loss: 0.3703, Value Loss: 0.3867\n",
      "Época [20/100], Train Loss: 0.1978, Value Loss: 0.1815\n",
      "Época [30/100], Train Loss: 0.1638, Value Loss: 0.1296\n",
      "Época [40/100], Train Loss: 0.1158, Value Loss: 0.1942\n",
      "Época [50/100], Train Loss: 0.1323, Value Loss: 0.0958\n",
      "Época [60/100], Train Loss: 0.1000, Value Loss: 0.0897\n",
      "Época [70/100], Train Loss: 0.1170, Value Loss: 0.0874\n",
      "Época [80/100], Train Loss: 0.1092, Value Loss: 0.2080\n",
      "Época [90/100], Train Loss: 0.0950, Value Loss: 0.1579\n",
      "Época [100/100], Train Loss: 0.0882, Value Loss: 0.2932\n"
     ]
    }
   ],
   "source": [
    "# Cross Entropy Loss\n",
    "lr = 0.01\n",
    "num_epochs = 100\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Modo de evaluación en datos de prueba\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Imprimir información de entrenamiento y validación\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Época [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Value Loss: {val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.0539, Value Loss: 0.0549\n",
      "Epoch [20/100], Train Loss: 0.0446, Value Loss: 0.0451\n",
      "Epoch [30/100], Train Loss: 0.0400, Value Loss: 0.0490\n",
      "Epoch [40/100], Train Loss: 0.0400, Value Loss: 0.0428\n",
      "Epoch [50/100], Train Loss: 0.0375, Value Loss: 0.0428\n",
      "Epoch [60/100], Train Loss: 0.0368, Value Loss: 0.0432\n",
      "Epoch [70/100], Train Loss: 0.0361, Value Loss: 0.0424\n",
      "Epoch [80/100], Train Loss: 0.0377, Value Loss: 0.0418\n",
      "Epoch [90/100], Train Loss: 0.0355, Value Loss: 0.0419\n",
      "Epoch [100/100], Train Loss: 0.0358, Value Loss: 0.0418\n"
     ]
    }
   ],
   "source": [
    "#  Mean Squared Error\n",
    "lr = 0.01\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets.view(-1, 1).float()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Evaluation mode on test data\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets.view(-1, 1))  \n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Print training and validation information\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Value Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.0175, Value Loss: 0.0236\n",
      "Epoch [20/100], Train Loss: 0.0176, Value Loss: 0.0208\n",
      "Epoch [30/100], Train Loss: 0.0173, Value Loss: 0.0245\n",
      "Epoch [40/100], Train Loss: 0.0177, Value Loss: 0.0225\n",
      "Epoch [50/100], Train Loss: 0.0172, Value Loss: 0.0219\n",
      "Epoch [60/100], Train Loss: 0.0170, Value Loss: 0.0222\n",
      "Epoch [70/100], Train Loss: 0.0175, Value Loss: 0.0210\n",
      "Epoch [80/100], Train Loss: 0.0169, Value Loss: 0.0208\n",
      "Epoch [90/100], Train Loss: 0.0169, Value Loss: 0.0207\n",
      "Epoch [100/100], Train Loss: 0.0170, Value Loss: 0.0211\n"
     ]
    }
   ],
   "source": [
    "#  Huber Loss\n",
    "lr = 0.01\n",
    "loss_function = nn.SmoothL1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets.view(-1, 1).float()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Evaluation mode on test data\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets.view(-1, 1))  # Ensure targets match output shape\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Print training and validation information\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Value Loss: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
